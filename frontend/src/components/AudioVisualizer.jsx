import React, { useState, useRef, useEffect, useCallback } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { Mic, MicOff, Loader2 } from 'lucide-react';

const API_BASE_URL = 'http://localhost:8000';

const AudioVisualizer = ({ 
  isActive = false, 
  onClick, 
  onTranscript, 
  onSuggestions,
  onStreamingText,  // æ–°å¢ï¼šå®æ—¶æµå¼æ–‡æœ¬å›è°ƒ
  onRecordingChange // æ–°å¢ï¼šå½•éŸ³çŠ¶æ€å˜åŒ–å›è°ƒ
}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [wsConnected, setWsConnected] = useState(false);
  const [streamingText, setStreamingText] = useState('');
  
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const wsRef = useRef(null);
  const clientIdRef = useRef(`client-${Date.now()}`);
  const streamIntervalRef = useRef(null);

  // é€šçŸ¥å½•éŸ³çŠ¶æ€å˜åŒ–
  useEffect(() => {
    if (onRecordingChange) {
      onRecordingChange(isRecording);
    }
  }, [isRecording, onRecordingChange]);

  // WebSocket è¿æ¥
  const connectWebSocket = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) return;

    const ws = new WebSocket(`ws://localhost:8000/ws/${clientIdRef.current}`);
    
    ws.onopen = () => {
      console.log('âœ… WebSocket è¿æ¥æˆåŠŸ');
      setWsConnected(true);
    };
    
    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data);
        
        // å¤„ç†æµå¼æ–‡æœ¬æ›´æ–°
        if (data.type === 'streaming_text') {
          setStreamingText(data.text);
          if (onStreamingText) {
            onStreamingText(data.text);
          }
        }
        
        // å¤„ç†å®Œæ•´è½¬å½•
        if (data.type === 'transcript' && onTranscript) {
          setStreamingText(''); // æ¸…ç©ºæµå¼æ–‡æœ¬
          onTranscript(data.data);
        }
        
        if (data.type === 'suggestions' && onSuggestions) {
          onSuggestions(data.data);
        }
      } catch (e) {
        console.error('WebSocket æ¶ˆæ¯è§£æå¤±è´¥:', e);
      }
    };
    
    ws.onclose = () => {
      console.log('âŒ WebSocket è¿æ¥å…³é—­');
      setWsConnected(false);
    };
    
    ws.onerror = (error) => {
      console.error('WebSocket é”™è¯¯:', error);
    };
    
    wsRef.current = ws;
  }, [onTranscript, onSuggestions, onStreamingText]);

  // ç»„ä»¶æŒ‚è½½æ—¶å°è¯•è¿æ¥ WebSocket
  useEffect(() => {
    connectWebSocket();
    
    return () => {
      if (wsRef.current) {
        wsRef.current.close();
      }
      if (streamIntervalRef.current) {
        clearInterval(streamIntervalRef.current);
      }
    };
  }, [connectWebSocket]);

  // å¼€å§‹å½•éŸ³
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      
      // æ£€æŸ¥æ”¯æŒçš„ MIME ç±»å‹
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
        ? 'audio/webm;codecs=opus'
        : MediaRecorder.isTypeSupported('audio/webm')
          ? 'audio/webm'
          : 'audio/ogg';
      
      console.log('ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', mimeType);
      
      const mediaRecorder = new MediaRecorder(stream, { mimeType });
      
      audioChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log(`æ”¶é›†éŸ³é¢‘å—: ${event.data.size} bytes, æ€»è®¡: ${audioChunksRef.current.length} å—`);
        }
      };
      
      mediaRecorder.onstop = async () => {
        console.log(`å½•éŸ³ç»“æŸï¼Œå…± ${audioChunksRef.current.length} ä¸ªéŸ³é¢‘å—`);
        if (audioChunksRef.current.length > 0) {
          await processAudio();
        }
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorderRef.current = mediaRecorder;
      // æ¯2ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®
      mediaRecorder.start(2000);
      setIsRecording(true);
      console.log('âœ… å¼€å§‹å½•éŸ³');
      
    } catch (error) {
      console.error('æ— æ³•è®¿é—®éº¦å…‹é£:', error);
      alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®\né”™è¯¯: ' + error.message);
    }
  };

  // åœæ­¢å½•éŸ³
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      console.log('ğŸ›‘ åœæ­¢å½•éŸ³');
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  // å¤„ç†éŸ³é¢‘
  const processAudio = async () => {
    if (audioChunksRef.current.length === 0) {
      console.log('æ²¡æœ‰éŸ³é¢‘æ•°æ®');
      return;
    }
    
    setIsProcessing(true);
    console.log('ğŸ”„ å¤„ç†éŸ³é¢‘...');
    
    try {
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      console.log(`éŸ³é¢‘å¤§å°: ${audioBlob.size} bytes`);
      
      // æ£€æŸ¥éŸ³é¢‘æ˜¯å¦å¤ªå°
      if (audioBlob.size < 1000) {
        console.log('éŸ³é¢‘å¤ªçŸ­ï¼Œè·³è¿‡å¤„ç†');
        setIsProcessing(false);
        return;
      }
      
      // è½¬æ¢ä¸º Base64
      const reader = new FileReader();
      
      reader.onloadend = async () => {
        const base64Audio = reader.result.split(',')[1];
        console.log(`Base64 é•¿åº¦: ${base64Audio.length}`);
        
        // ä¼˜å…ˆä½¿ç”¨ HTTP APIï¼ˆæ›´ç¨³å®šï¼‰
        await sendViaHttp(base64Audio);
        
        setIsProcessing(false);
      };
      
      reader.onerror = (error) => {
        console.error('FileReader é”™è¯¯:', error);
        setIsProcessing(false);
      };
      
      reader.readAsDataURL(audioBlob);
      
    } catch (error) {
      console.error('éŸ³é¢‘å¤„ç†å¤±è´¥:', error);
      setIsProcessing(false);
    }
  };

  // HTTP API å‘é€éŸ³é¢‘
  const sendViaHttp = async (base64Audio) => {
    console.log('ğŸ“¤ å‘é€éŸ³é¢‘åˆ°æœåŠ¡å™¨...');
    
    try {
      const response = await fetch(`${API_BASE_URL}/api/transcribe`, {
        method: 'POST',
        headers: { 
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({
          audio_data: base64Audio,
          sample_rate: 16000,
          format: 'webm'
        })
      });
      
      console.log('æœåŠ¡å™¨å“åº”çŠ¶æ€:', response.status);
      
      if (response.ok) {
        const data = await response.json();
        console.log('âœ… è½¬å½•ç»“æœ:', data);
        
        if (data.text && data.text.trim()) {
          if (onTranscript) {
            onTranscript(data);
          }
        } else {
          console.log('âš ï¸ è½¬å½•ç»“æœä¸ºç©º');
        }
      } else {
        const errorText = await response.text();
        console.error('âŒ æœåŠ¡å™¨é”™è¯¯:', response.status, errorText);
      }
    } catch (error) {
      console.error('âŒ HTTP è¯·æ±‚å¤±è´¥:', error);
      // å°è¯• WebSocket ä½œä¸ºå¤‡é€‰
      if (wsRef.current?.readyState === WebSocket.OPEN) {
        console.log('å°è¯• WebSocket å‘é€...');
        wsRef.current.send(JSON.stringify({
          type: 'audio',
          audio_data: base64Audio,
          sample_rate: 16000
        }));
      }
    }
  };

  // å¤„ç†ç‚¹å‡»
  const handleClick = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
    
    if (onClick) {
      onClick(!isRecording);
    }
  };

  return (
    <div className="fixed bottom-10 left-1/2 -translate-x-1/2 z-50 flex flex-col items-center gap-4">
      
      {/* Status Text */}
      <AnimatePresence>
        {(isRecording || isProcessing) && (
          <motion.div 
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: 10 }}
            className="flex items-center gap-2 text-xs font-medium text-slate-500 dark:text-zinc-400 tracking-wide"
          >
            {isProcessing ? (
              <>
                <Loader2 size={12} className="animate-spin" />
                å¤„ç†ä¸­...
              </>
            ) : (
              <>
                <span className="w-2 h-2 rounded-full bg-red-500 animate-pulse" />
                æ­£åœ¨å½•éŸ³...
              </>
            )}
          </motion.div>
        )}
      </AnimatePresence>

      {/* Connection Status */}
      <div className={`text-[10px] ${wsConnected ? 'text-green-500' : 'text-slate-400'}`}>
        {wsConnected ? 'â— å®æ—¶è¿æ¥' : 'â—‹ ç¦»çº¿æ¨¡å¼'}
      </div>

      {/* Button */}
      <button 
        onClick={handleClick}
        disabled={isProcessing}
        className={`
          relative flex items-center justify-center w-16 h-16 rounded-full 
          transition-all duration-300 focus:outline-none cursor-pointer
          ${isRecording 
            ? 'bg-red-500 text-white shadow-lg shadow-red-500/30' 
            : isProcessing
              ? 'bg-slate-300 dark:bg-zinc-700 text-slate-500'
              : 'bg-white text-slate-900 dark:bg-zinc-800 dark:text-zinc-300 shadow-md hover:shadow-lg border border-slate-200 dark:border-zinc-700'}
        `}
      >
        {/* Pulse Ring (Recording State) */}
        {isRecording && (
          <motion.div
            className="absolute inset-0 rounded-full border-2 border-red-500/50"
            animate={{ scale: [1, 1.5], opacity: [0.8, 0] }}
            transition={{ duration: 1.2, repeat: Infinity }}
          />
        )}

        {isProcessing ? (
          <Loader2 size={24} className="animate-spin" />
        ) : isRecording ? (
          <MicOff size={24} strokeWidth={1.5} />
        ) : (
          <Mic size={24} strokeWidth={1.5} />
        )}
      </button>
    </div>
  );
};

export default AudioVisualizer;
